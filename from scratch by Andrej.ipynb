{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34419ed8-6aa2-4471-b4df-11cc7586404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae770fa-d7aa-46a5-a451-469ccca859cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read tiny shakespeare dataset\n",
    "with open(\"tiny shakespeare dataset.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b964a836-bb7a-4227-bb9c-e0b1a30d117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27cd9840-babd-4109-872c-bb22f3aad8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fcff81-ae1c-4d0e-bb1c-670c39f46f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unqiue characters are:  \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "How many unique characters:  65\n"
     ]
    }
   ],
   "source": [
    "# check all the unique characters in the first 1000 characters\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"The unqiue characters are: \", \"\".join(chars)) #including space and \\n\n",
    "print(\"How many unique characters: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6861af3-b909-4675-a0e6-46d783ed0d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 1, 58, 46, 43, 56, 43]\n",
      "hi there\n"
     ]
    }
   ],
   "source": [
    "# a simple tokenisation, we do have other encoding techniques like sentencePiece by google, tiktoken by OpenAI(these are sub-word tokenisation)\n",
    "# create a mapping from characters to integers\n",
    "str_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_str = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [str_to_int[c] for c in s] #encoder: take a string, output a list of integers\n",
    "decode = lambda l: \"\".join([int_to_str[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hi there\"))\n",
    "print(decode(encode(\"hi there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e045b00-a0c3-4f63-97d7-a42bb019c3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# encode the entire dataset and store it into a tensor\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9261d424-8d1c-426c-8867-99a0b605e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) #first 90% will be train, rest validation\n",
    "train = data[:n]\n",
    "test = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859cf5ee-0eee-4d9b-9b79-4d8831a40f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([111540])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3232bbb6-c140-43b2-867b-98174515e71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a3e0a4-ea82-4f06-bdc8-c53254f34319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target is: 47\n",
      "when input is tensor([18, 47]) the target is: 56\n",
      "when input is tensor([18, 47, 56]) the target is: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target is: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is: 58\n"
     ]
    }
   ],
   "source": [
    "# an ilustration of time dimension\n",
    "x = train[:block_size]\n",
    "y = train[1:block_size+1] # y is train data position + 1\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d511e84c-e159-4707-b55a-2e088e7b80cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "------\n",
      "when input is [24] the target is 43\n",
      "when input is [24, 43] the target is 58\n",
      "when input is [24, 43, 58] the target is 5\n",
      "when input is [24, 43, 58, 5] the target is 57\n",
      "when input is [24, 43, 58, 5, 57] the target is 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the target is 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the target is 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target is 39\n",
      "when input is [44] the target is 53\n",
      "when input is [44, 53] the target is 56\n",
      "when input is [44, 53, 56] the target is 1\n",
      "when input is [44, 53, 56, 1] the target is 58\n",
      "when input is [44, 53, 56, 1, 58] the target is 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the target is 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the target is 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target is 1\n",
      "when input is [52] the target is 58\n",
      "when input is [52, 58] the target is 1\n",
      "when input is [52, 58, 1] the target is 58\n",
      "when input is [52, 58, 1, 58] the target is 46\n",
      "when input is [52, 58, 1, 58, 46] the target is 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the target is 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the target is 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target is 46\n",
      "when input is [25] the target is 17\n",
      "when input is [25, 17] the target is 27\n",
      "when input is [25, 17, 27] the target is 10\n",
      "when input is [25, 17, 27, 10] the target is 0\n",
      "when input is [25, 17, 27, 10, 0] the target is 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the target is 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the target is 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target is 39\n"
     ]
    }
   ],
   "source": [
    "# an ilustration of batch dimension\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # the maximum context for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of input x and target y\n",
    "    data = train if split == \"train\" else test\n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,)) #size, max value, dtype\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "for b in range(batch_size): #batch dimension\n",
    "    for t in range(block_size): #time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.numpy().tolist()} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9733cbff-9474-4260-921c-400435812bfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m             idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((idx, idx_next), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#(B, T+1)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m idx\n\u001b[1;32m---> 41\u001b[0m m \u001b[38;5;241m=\u001b[39m BigramLanguageModel(vocab_size)\n\u001b[0;32m     42\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m m(xb, yb)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m#(32, 65) 32(batch_size*block_size), with 65 possible vacabulary elements\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a loopup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(B,T,C)batch, time, channel, 4,8,65\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape #reshape the logits for Pytorch according to its requirement\n",
    "            logits = logits.view(B*T, C) #reshape the logits to match cross entropy parameter for loss calculation\n",
    "            targets = targets.view(B*T)  #reshape the targets to match cross entropy parameter for loss calculation\n",
    "            loss = F.cross_entropy(logits, targets) #measures the quality of the model\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens): #idx is the current context in a batch\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        # so each time we randomly take 4 sentences from the corpus as a batch, each sentence has 8 characters\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the prediction, loss will be ignored because we have no groundtruth\n",
    "            logits, loss = self(idx) #self = call the function of class, take the logits and loss from above.\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] #becoms (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim = -1) #(B, C), calculate (4, 8) logits probability by softmax\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) #(B, 1), calculate multinomial probability distributions\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim = 1) #(B, T+1)\n",
    "        return idx\n",
    "        \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape) #(32, 65) 32(batch_size*block_size), with 65 possible vacabulary elements\n",
    "print(loss) #mean of loss\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long) #zeros(1,1) returns a tensor that has 1 row and 1 column\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist())) #the prediction is only based on last the character, not entire prior sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce76f1f7-1a4a-4fa6-88d5-7378fcedf63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "optimiser = torch.optim.AdamW(m.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c839c24d-135d-40a0-9a46-4f6b61980d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6319539546966553\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(10000):\n",
    "\n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    #evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimiser.zero_grad(set_to_none=True) #Resets the gradients of all optimized, \n",
    "    #this will in general have lower memory footprint, and can modestly improve performance. \n",
    "    loss.backward() #getting the gradients for all the parameters\n",
    "    optimiser.step() #use the gradients to update the parameters\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51af4725-549c-4604-abe5-0242830c5859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "waucrdidsth ast cor n y d hys, tinefurd t Oruby aves O:\n",
      "\n",
      "u?\n",
      "Toutlagrer t phthel e\n",
      "D amowestha toford t dee are coveauck, wlstongerethestho\n",
      "\n",
      "\n",
      "A ay ariseg d, art, ch isut dell vemed, hekemenouresat\n",
      "Touns towiseellat s.\n",
      "\n",
      "I tha hontsth ICIUThache: my, the be it ourearldyewrqu ABulmisphilir y hyor ond oundle ompe Pe o m P: somistrou, paburoinsee\n",
      "Londer wathes 's, mayousorntekeawhart ghruremin whell y angr hinnds oupre hingo, foune:\n",
      "s hase!\n",
      "NS:\n",
      "Stho lereer atiswouese?\n",
      "\n",
      "\n",
      "He'cindine u'sold ngnfithot pon\n"
     ]
    }
   ],
   "source": [
    "# we can see the model starts making progress and learn to form shakespear sentences, even though it's still garbage.\n",
    "print(decode(m.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e4764-bc36-41f1-86f3-c78aa509650a",
   "metadata": {},
   "source": [
    "#### so far we are only using last character to predict next character\n",
    "#### we want to make a model that the tokens can connect to each other, by using the history prediction(all the tokens before the prediction) to make new prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b409d8-ffa9-4484-8d00-c3270ed4f38c",
   "metadata": {},
   "source": [
    "### Self-attention demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce3ab354-84b8-4373-a7ee-0b6ff0c28ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n",
      "tensor([[ 1.9269,  1.4873],\n",
      "        [ 0.9007, -2.1055],\n",
      "        [ 0.6784, -1.2345],\n",
      "        [-0.0431, -1.6047],\n",
      "        [-0.7521,  1.6487],\n",
      "        [-0.3925, -1.4036],\n",
      "        [-0.7279, -0.5594],\n",
      "        [-0.7688,  0.7624]])\n"
     ]
    }
   ],
   "source": [
    "# version 1: the mathematical trick in self-attention(i.e. how to make prediciton based on previous history context)\n",
    "torch.manual_seed(42)\n",
    "B,T,C = 4,8,2 #batch, time, channels, 4 batch, each batch have 8 times(rows, tokens) and 2 channals(columns)\n",
    "x = torch.randn(B,T,C)\n",
    "print(x.shape)\n",
    "print(x[0]) #check a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28b756f-6032-46ad-9e2a-1d46e8a09719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9269,  1.4873],\n",
      "        [ 1.4138, -0.3091],\n",
      "        [ 1.1687, -0.6176],\n",
      "        [ 0.8657, -0.8644],\n",
      "        [ 0.5422, -0.3617],\n",
      "        [ 0.3864, -0.5354],\n",
      "        [ 0.2272, -0.5388],\n",
      "        [ 0.1027, -0.3762]])\n"
     ]
    }
   ],
   "source": [
    "# we want x[b,t] = mean_{i<=t}, x[b,i]\n",
    "xbow = torch.zeros((B,T,C)) #x bag of words, average up the numbers above\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] #(t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)# average the time dimension\n",
    "print(xbow[0]) #check a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a41c92a8-3207-4e0d-a25e-95567e25905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "---\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# a toy example of matrix multiplication \n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3)) #generate 3x3 tensor with value 1\n",
    "a = a / torch.sum(a, 1, keepdim=True) # normalise a\n",
    "b = torch.randint(0, 10, (3,2)).float() #generate 3x2 tensor with value 1 to 10\n",
    "c = a @ b # @ is matrix multiplication, 3x3 * 3x2\n",
    "\n",
    "print(torch.tril(torch.ones(3,3))) # this will give us a triangular tensor)\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"---\")\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"---\")\n",
    "print(\"c=\")\n",
    "print(c) # first row in a : 14 = 1*2 + 1*6 + 1*6, 16 = 1*7 + 1*4 + 1*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e92bed54-171c-4017-b51c-70c497e80497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.9269,  1.4873],\n",
       "         [ 1.4138, -0.3091],\n",
       "         [ 1.1687, -0.6176],\n",
       "         [ 0.8657, -0.8644],\n",
       "         [ 0.5422, -0.3617],\n",
       "         [ 0.3864, -0.5354],\n",
       "         [ 0.2272, -0.5388],\n",
       "         [ 0.1027, -0.3762]]),\n",
       " tensor([[ 1.9269,  1.4873],\n",
       "         [ 1.4138, -0.3091],\n",
       "         [ 1.1687, -0.6176],\n",
       "         [ 0.8657, -0.8644],\n",
       "         [ 0.5422, -0.3617],\n",
       "         [ 0.3864, -0.5354],\n",
       "         [ 0.2272, -0.5388],\n",
       "         [ 0.1027, -0.3762]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: this proves that matrix multiplication generates the same result as mathematical trick\n",
    "# a \n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "# c\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) => (B, T, C)\n",
    "print(torch.allclose(xbow, xbow2))\n",
    "xbow[0], xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d44fc7e-b4c3-4e46-aec5-91009a5c3aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 3: use softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float(\"-inf\"))\n",
    "print(wei) # every 0 in tril will become negative infinity\n",
    "wei = F.softmax(wei, dim=-1) # softmax does sum of exponantiate of the row, and normalise\n",
    "print(wei)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1989ac4-4503-42fb-ac6a-00ee12b5a836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 4: self-attention\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "#lets see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "value = nn.Linear(C, head_size, bias = False)\n",
    "k = key(x) #(B,T,16)\n",
    "q = query(x) #(B,T,16)\n",
    "wei = q @ k.transpose(-2,-1) #(B, T, 16) @ (B, 16, T) => (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float(\"-inf\"))\n",
    "#print(wei) # every 0 in tril will become negative infinity\n",
    "wei = F.softmax(wei, dim=-1) # softmax does sum of exponantiate of the row, and normalise\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36f72ade-b5f2-412d-b639-3ef064cb46f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b50884-d01e-437e-b270-266a62e5ce3c",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "##### 1. Attention is a communication mechanism. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "##### 2. There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "##### 3. Each example across batch dimension is of course processed completely independent and never talked to each other.\n",
    "##### 4. In an \"encoder\" attention block just delete the single line that does masking with tril, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and its usually used in autoregressive settings, like language modelling.\n",
    "##### 5. \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source(e.g. an encoder module)\n",
    "##### 6. \"Scaled\" attention additionally divides wei by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and softmax will stay diffuse and not saturate too much, illustration below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccba25d4-0f4e-49ed-966a-2f1df24b6a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0632)\n",
      "tensor(0.9891)\n",
      "tensor(15.6088)\n",
      "tensor(0.9755)\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1)#*head_size**-0.5\n",
    "wei2 = q @ k.transpose(-2, -1) * head_size**-0.5 # according to the paper attention is all you need, the variance will be around 1\n",
    "print(k.var())\n",
    "print(q.var())\n",
    "print(wei.var())\n",
    "print(wei2.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02d118d0-9bdd-4245-9654-61e342d2c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "    \n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias = False) #create linear layers for key\n",
    "        self.query = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x) #(B,T,C)\n",
    "        q = self.query(x) #(B,T,C)\n",
    "        #compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5 #(B, T, 16) @ (B, 16, T) => (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\")) #(B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) #(B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        #perform the weighted aggregation of the values\n",
    "        v = self.value(x) #(B,T,C)\n",
    "        out = wei @ v #(B,T,T) @ (B,T,C) => (B,T,C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6bdbda70-e14f-4d4e-85e1-33080e24962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"multiple head of self-attention in parallel, for inter-tokens communication\"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e29fddb4-335e-469d-a3cc-4f93cebd32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"a simple linear layer followed by a non -linearity, for computation and processing the communication\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3bb84d48-888d-4934-91de-7a8ef09904bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer block: communication followed by computation\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        #n_embd: embedding dimension, n_head: the number of heads we would like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba139bd3-042b-4267-a45d-e816298400c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.788929 M parameters\n",
      "step 0: train loss 4.2221, val loss 4.2306\n",
      "step 500: train loss 1.7408, val loss 1.9037\n",
      "step 1000: train loss 1.3969, val loss 1.6108\n",
      "step 1500: train loss 1.2666, val loss 1.5282\n",
      "step 2000: train loss 1.1863, val loss 1.5044\n",
      "step 2500: train loss 1.1242, val loss 1.5011\n",
      "step 3000: train loss 1.0723, val loss 1.4840\n",
      "step 3500: train loss 1.0186, val loss 1.5046\n",
      "step 4000: train loss 0.9592, val loss 1.5073\n",
      "step 4500: train loss 0.9141, val loss 1.5465\n",
      "\n",
      "\n",
      "Shepherd:\n",
      "From not, sir; he were a Claudio's knave:\n",
      "and the sea-side; let the princes habit him, here ever\n",
      "lely. Let him that he would live that velf you, she\n",
      "In one guard's apt and him. Yea, mine, Lord Master Angelo is his, but\n",
      "which being affects, these eyes first buzard,\n",
      "both be most fleshore abspinate, a notary beast\n",
      "the humility of his friends: they channish\n",
      "them walk branch. Fare ye welcome no more but thine own: matter with us;\n",
      "the carbune make dischance a brace, now 'tis they bragging. \n"
     ]
    }
   ],
   "source": [
    "# a full script from above, a super simple bigram model\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # the maximum context for predictions\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #for GPU computing\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "#-----------------------------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "with open(\"tiny shakespeare dataset.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occured in this corpus\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "#encode the corpus\n",
    "str_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_str = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [str_to_int[c] for c in s] #encoder: take a string, output a list of integers\n",
    "decode = lambda l: \"\".join([int_to_str[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "#convert the corpus into tensors, train and test split\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "n = int(0.9*len(data)) #first 90% will be train, rest validation\n",
    "train = data[:n]\n",
    "test = data[n:]\n",
    "#------------------------------------\n",
    "#data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of input x and target y\n",
    "    data = train if split == \"train\" else test\n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,)) #size, max value, dtype\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device) #for GPU computing\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad() #context manager to reduce remory usage, tell pytorch no back-propagation in this function \n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X,Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "# super simple bigram model\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) #final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size) # need a linear layer to make token embeddings to logits\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) #(B,T,C)batch, time, channel, 4,8,65\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) #T,C\n",
    "        x = tok_emb + pos_emb #(B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) #(B,T,vocab_size), the decoder\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape #reshape the logits for Pytorch according to its requirement\n",
    "            logits = logits.view(B*T, C) #reshape the logits to match cross entropy parameter for loss calculation\n",
    "            targets = targets.view(B*T)  #reshape the targets to match cross entropy parameter for loss calculation\n",
    "            loss = F.cross_entropy(logits, targets) #measures the quality of the model\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens): #idx is the current context in a batch\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        # so each time we randomly take 4 sentences from the corpus as a batch, each sentence has 8 characters\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the prediction, loss will be ignored because we have no groundtruth\n",
    "            logits, loss = self(idx_cond) #self = call the function of class, take the logits and loss from above.\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] #becoms (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim = -1) #(B, C), calculate (4, 8) logits probability by softmax\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) #(B, 1), calculate multinomial probability distributions\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim = 1) #(B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = GPTLanguageModel()\n",
    "m = model.to(device) #for GPU computing\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "#create a pytorch optimiser\n",
    "optimiser = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# make a training loop\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    #every once in a while evaluate the loss on train and test sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses[\"train\"]:.4f}, val loss {losses[\"test\"]:.4f}\")\n",
    "\n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    #evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimiser.zero_grad(set_to_none=True) #Resets the gradients of all optimized, \n",
    "    #this will in general have lower memory footprint, and can modestly improve performance. \n",
    "    loss.backward() #getting the gradients for all the parameters\n",
    "    optimiser.step() #use the gradients to update the parameters\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device) #zeros(1,1) returns a tensor that has 1 row and 1 column, GPU computing\n",
    "print(decode(m.generate(context, max_new_tokens=3000)[0].tolist())) #the prediction is only based on last the character, not entire prior sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
